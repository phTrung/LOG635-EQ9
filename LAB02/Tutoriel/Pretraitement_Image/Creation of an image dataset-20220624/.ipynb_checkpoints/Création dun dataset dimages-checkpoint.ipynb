{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"red\">Création d'un</font> _dataset_ d'images\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always run this cell to display the complete output in the cells, not just the last result.\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après ce tuto, vous pourrez:\n",
    "\n",
    "* Manipulez des images avec OpenCV.\n",
    "* Apportez des modifications aux images et appliquez des  méthodes d’augmentation des données.\n",
    "* Créer votre propre dataset d'images pour l'apprentissage automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color=\"red\">1 | LES</font> PAQUETS\n",
    "---\n",
    "Importons d’abord tous les packages dont vous aurez besoin:\n",
    "\n",
    "* [pathlib](https://docs.python.org/3/library/pathlib.html) : Des classes représentant des chemins de système de fichiers avec une sémantique appropriée pour différents systèmes d'exploitation.\n",
    "* [mathplotlib](https://matplotlib.org/) : C'est une bibliothèque pour tracer des graphiques en Python.\n",
    "* [cv2](https://github.com/skvark/opencv-python) : Unofficial pre-built OpenCV packages for Python.\n",
    "* [numpy](https://numpy.org/) : Extension destinée à manipuler des matrices ou tableaux multidimensionnels ainsi que des fonctions mathématiques opérant sur ces tableaux.\n",
    "* [imutils](https://pypi.org/project/imutils/): Une série de fonctions pratiques permettant de simplifier les fonctions de traitement d’images\n",
    "* [random](https://docs.python.org/3/library/random.html) : Ce module implémente des générateurs de nombres pseudo-aléatoires pour diverses distributions.\n",
    "* [pickle]() : Ce module permet de sauvegarder dans un fichier, au format binaire,  n'importe quel objet Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import imutils\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color=\"red\"> 2 | NOTIONS DE BASE</font> SUR OpenCV\n",
    "---\n",
    "OpenCV (Open Source Computer Vision Library) est une bibliothèque dotée de nombreuses fonctionnalités, outils, algorithmes et utilitaires permettant de gérer les images et les ressources associées aux images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the image used in the examples\n",
    "path = Path.cwd() / \"images\" / \"124_Circle2.jpg\"\n",
    "\n",
    "# Reading the image\n",
    "image = cv2.imread(str(path))\n",
    "type(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le constater, les images sont lues comme des tableaux `numpy` ordinaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image shape shows image size (width, heigth, color chanels)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the image at any moment with `matplotlib` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot image\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.1 - Transformation du</font> format RBG to RGB\n",
    "---\n",
    "OpenCV utilise le format de pixel BGR par défaut. Le standard le plus courant pour les ordinateurs et les bibliothèques (comme matplotlib) est le RGB. La conversion de BGR en RGB est simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BGR to RGB\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Plot image\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.2 - Image en</font> niveau de gris\n",
    "---\n",
    "Nous pouvons utiliser une approche similaire pour transformer notre image en niveau de gris: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB to Grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Plot image\n",
    "plt.imshow(gray_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color image size\n",
    "image.shape\n",
    "\n",
    "# Gray image size\n",
    "gray_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que l'image en niveaux de gris n'a qu'un seul canal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.3 - Redimensionnement</font> d'images\n",
    "---\n",
    "Le redimensionnement des images est important pour plusieurs raisons:\n",
    "\n",
    "* Tout d'abord, vous voudrez peut-être redimensionner une grande image pour qu'elle tienne sur votre écran.\n",
    "\n",
    "* Le traitement des images est également plus rapide sur les images plus petites car il y a moins de pixels à traiter. \n",
    "\n",
    "* Dans le cas du *Deep Learning*, nous redimensionnons souvent les images, en ignorant les proportions, afin que le volume s'intègre dans un réseau nécessitant des images de certaines dimensions.\n",
    "\n",
    "Notez que le redimensionnement déformera un peu l'image. Il est important d'analyser cet effet au cours de la phase exploratoire, car il peut avoir un effet négatif sur les résultats de votre modèle. Les fleurs et les animaux peuvent convenir avec un peu d’étirement ou de compression, mais pas les primitives du visage.\n",
    "\n",
    "Cela peut se produire lorsque les dimensions de l'image d'origine ne correspondent pas exactement à la taille souhaitée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH = 160\n",
    "HEIGHT = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Resize, ignoring aspect ratio\n",
    "resized = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "\n",
    "# Plot image\n",
    "plt.imshow(resized)\n",
    "\n",
    "# Image size\n",
    "resized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.4 - Rééchelonnement</font> d'images\n",
    "---\n",
    "Essayons une autre stratégie de redimensionnement de l’image et de maintien des proportions.\n",
    "\n",
    "Si vous imaginez des images de portrait par rapport à des images de paysage, vous saurez que beaucoup de choses peuvent être gâchées par un redimensionnement glissant. \n",
    "\n",
    "Le _rescaling_ consiste à supposer que vous verrouillez les proportions pour éviter toute distorsion de l’image. Dans ce cas, nous réduirons l’image du côté le plus court qui correspond à la taille d’entrée du modèle.\n",
    "\n",
    "* Paysage: limiter le redimensionnement par la hauteur\n",
    "* Portrait: limiter le redimensionnement par la largeur\n",
    "\n",
    "À ce stade, une seule dimension est définie selon les besoins de l’entrée du modèle. Nous avons encore besoin de couper un côté pour faire un carré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = image.shape[1] / float(image.shape[0])\n",
    "print(aspect)\n",
    "\n",
    "if aspect > 1:\n",
    "    # landscape orientation - wide image    \n",
    "    res = int(HEIGHT * aspect)\n",
    "    scaled = cv2.resize(image, (res, HEIGHT))\n",
    "if aspect < 1:    \n",
    "    # portrait orientation - tall image\n",
    "    res = int(WIDTH * aspect)\n",
    "    scaled = cv2.resize(image, (res, WIDTH))\n",
    "if aspect == 1:\n",
    "    scaled = cv2.resize(image, (WIDTH, HEIGHT))\n",
    "\n",
    "# show image\n",
    "plt.imshow(scaled)\n",
    "print(scaled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.5 - Retournement</font> d'images\n",
    "---\n",
    "La prochaine étape sur nos transformations d’image à explorer est le retournement d’une image. Nous pouvons retourner une image autour de l'axe des x ou des y, ou les deux.\n",
    "\n",
    "Comment retourner une image s’explique mieux en regardant la sortie du code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipVertical = cv2.flip(image, 0)\n",
    "plt.imshow(flipVertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipHorizontal = cv2.flip(image, 1)\n",
    "plt.imshow(flipHorizontal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flipBoth = cv2.flip(image, -1)\n",
    "plt.imshow(flipBoth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.6 - Assombrir et éclaircir</font> les images\n",
    "---\n",
    "Ces actions sont réalisées à l'aide d'arithmétique d'image. En partant du fait que les images ne sont que des matrices numériques, vous pouvez effectuer des opérations telles que l’ajout ou la soustraction de valeurs à chacun de ses éléments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.ones(image.shape, dtype = \"uint8\") * 100\n",
    "added = cv2.add(image, M)\n",
    "\n",
    "M = np.ones(image.shape, dtype = \"uint8\") * 50\n",
    "subtracted = cv2.subtract(image, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(added)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notez que l’image semble plus «délavée» et est nettement plus lumineuse que l’original. En effet, nous augmentons les intensités de pixels en leur ajoutant 100 et en les poussant vers des couleurs plus vives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(subtracted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre image semble maintenant beaucoup plus sombre que l'original. Les pixels autrefois blancs sont maintenant gris. En effet, nous soustrayons 50 pixels et les poussons vers les régions les plus sombres de l'espace colorimétrique RGB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">2.7 - Rotation</font>\n",
    "---\n",
    "La rotation correspond exactement à ce que cela ressemble : faire pivoter une image d’un angle donné. Dans cette section, nous verrons comment faire pivoter une image.\n",
    "\n",
    "Lorsque nous faisons pivoter une image, nous devons spécifier autour du point que nous voulons faire pivoter. Dans la plupart des cas, vous souhaiterez effectuer une rotation autour du centre de l'image. Cependant, OpenCV vous permet de spécifier tout point arbitraire sur lequel vous souhaitez faire pivoter.\n",
    "\n",
    "Nous définissons une matrice pour faire pivoter l'image. Au lieu de construire manuellement la matrice avec numpy, nous allons simplement appeler la méthode `cv2.getRotationMatrix2D`.\n",
    "\n",
    "Une fois que nous avons notre matrice de rotation M de la fonction `cv2.getRotationMatrix2D`, nous pouvons appliquer la rotation à notre image à l’aide de `cv2.warpAffine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting image size\n",
    "w, h  = image.shape[:2]\n",
    "\n",
    "# Rotations angle\n",
    "angle = 45\n",
    "\n",
    "# Scaling factor\n",
    "scale = 1\n",
    "\n",
    "# Image center\n",
    "center = (w / 2, h / 2)\n",
    "\n",
    "M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "\n",
    "# Image rotation\n",
    "rotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "image.shape\n",
    "plt.imshow(rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color=\"red\">3 | DÉTECTION</font> DES FORMES\n",
    "---\n",
    "Dans cette section, nous allons créer un détecteur de forme pour détecter les formes de certains marqueurs de Cozmo. \n",
    "\n",
    "![cozmo_custom_markers](images/cozmo_custom_markers.jpg)\n",
    "\n",
    "La première étape dans la construction de notre détecteur de forme consiste à écrire du code pour encapsuler la logique d’identification de formes.\n",
    "\n",
    "Définissons notre méthode `detect_shape` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_shape(contour):\n",
    "    # initialize the shape name and approximate the contour\n",
    "    shape = \"unidentified\"\n",
    "    peri = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.04 * peri, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons notre méthode de détection qui ne nécessite qu'un seul argument, le contour de la forme que nous essayons d'identifier.\n",
    "\n",
    "Pour effectuer la détection de forme, nous utiliserons l’approximation des contours.\n",
    "\n",
    "Comme son nom l'indique, l'approximation des contours est un algorithme permettant de réduire le nombre de points d'une courbe avec un ensemble de points réduit, d'où l'appellation d'approximation.\n",
    "\n",
    "Cet algorithme est généralement appelé algorithme de [Ramer-Douglas-Peucker](https://fr.wikipedia.org/wiki/Algorithme_de_Douglas-Peucker), ou simplement _split-and-merge algorithm_.\n",
    "\n",
    "L’approximation du contour est fondée sur l’hypothèse qu’une courbe peut être approchée par une série de segments de ligne courts. Cela conduit à une courbe approximative résultante qui consiste en un sous-ensemble de points définis par la crue originale.\n",
    "\n",
    "L’approximation du contour est en réalité déjà implémentée dans OpenCV via la méthode `cv2.approxPolyDP`.\n",
    "Pour effectuer l'approximation des contours, nous calculons d'abord le périmètre du contour (**ligne 4**), puis construisons l'approximation réelle des contours (**ligne 5**).\n",
    "\n",
    "Les valeurs communes pour le second paramètre de `cv2.approxPolyDP` sont normalement comprises entre 1 et 5% du périmètre de contour d'origine.\n",
    "\n",
    "Étant donné notre contour approximatif, nous pouvons passer à la détection de forme:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_shape(contour):\n",
    "    # initialize the shape name and approximate the contour\n",
    "    shape = \"unidentified\"\n",
    "    peri = cv2.arcLength(contour, True)\n",
    "    approx = cv2.approxPolyDP(contour, 0.04 * peri, True)\n",
    "    \n",
    "    # if the shape is a triangle, it will have 3 vertices\n",
    "    if len(approx) == 3:\n",
    "        shape = \"triangle\"\n",
    "\n",
    "    # if the shape has 4 vertices, it is either a square or\n",
    "    # a rectangle\n",
    "    elif len(approx) == 4:\n",
    "        # compute the bounding box of the contour and use the\n",
    "        # bounding box to compute the aspect ratio\n",
    "        (x, y, w, h) = cv2.boundingRect(approx)\n",
    "        ar = w / float(h)\n",
    "\n",
    "        # a square will have an aspect ratio that is approximately\n",
    "        # equal to one, otherwise, the shape is a rectangle\n",
    "        shape = \"square\" if ar >= 0.95 and ar <= 1.05 else \"diamond\"\n",
    "\n",
    "    # if the shape is a pentagon, it will have 5 vertices\n",
    "    elif len(approx) == 5:\n",
    "        shape = \"hexagon\"\n",
    "\n",
    "    # otherwise, we assume the shape is a circle\n",
    "    else:\n",
    "        shape = \"circle\"\n",
    "\n",
    "    # return the name of the shape\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est important de comprendre qu’un contour consiste en une liste de sommets. Nous pouvons vérifier le nombre d'entrées dans cette liste pour déterminer la forme d'un objet.\n",
    "\n",
    "Par exemple, si le contour approximatif a trois sommets, il doit alors s'agir d'un triangle (**lignes 8 et 9**).\n",
    "\n",
    "Si un contour a quatre sommets, il doit s'agir d'un carré ou d'un rectangle (**ligne 13**). Pour déterminer lequel, nous calculons le rapport d'aspect, qui est simplement la largeur du cadre de contour divisé par la hauteur (**lignes 16 et 17**). Si le rapport d'aspect est ~ 1,0, nous examinons un carré (puisque tous les côtés ont une longueur approximativement égale). Sinon, la forme est un rectangle.\n",
    "\n",
    "Si un contour a six sommets, on peut le qualifier d'hexagone (**lignes 24 et 25**).\n",
    "\n",
    "Sinon, par processus d'élimination (dans le contexte de cet exemple, bien sûr), nous pouvons supposer que la forme que nous examinons est un cercle (**lignes 28 et 29**).\n",
    "\n",
    "Enfin, nous renvoyons la forme identifiée à la méthode appelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">3.1 - Détection</font> avec OpenCV\n",
    "---\n",
    "Commençons pour le prétraitement de notre image :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and resize it to a smaller factor so that\n",
    "# the shapes can be approximated better\n",
    "image = cv2.imread(\"cozmo_custom_markers.jpg\")\n",
    "bitwise = cv2.bitwise_not(image)\n",
    "resized = imutils.resize(bitwise, width=300)\n",
    "ratio = image.shape[0] / float(resized.shape[0])\n",
    "\n",
    "# convert the resized image to grayscale, blur it slightly,\n",
    "# and threshold it\n",
    "gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "# find contours in the thresholded image and initialize the\n",
    "# shape detector\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout d'abord, nous chargeons notre image et la redimensionnons. Nous suivons ensuite le ratio de l'ancienne hauteur par rapport à la nouvelle hauteur redimensionnée, nous verrons exactement pourquoi nous faisons cela plus loin dans le tutoriel.\n",
    "\n",
    "De là, les **lignes 10-12** gèrent la conversion de l'image redimensionnée en niveaux de gris, en la lissant pour réduire le bruit à haute fréquence, et finalement en la seuilant pour révéler les formes dans l'image.\n",
    "\n",
    "Après le seuillage, notre image devrait ressembler à ceci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarquez comment notre image a été binarisée, les formes apparaissent comme un premier plan blanc sur un fond noir.\n",
    "\n",
    "Enfin, nous trouvons des contours dans notre image binaire, gérons la saisie de la valeur de tuple correcte dans `cv2.findContours` à partir de notre version OpenCV.\n",
    "\n",
    "La dernière étape consiste à identifier chacun des contours :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    # compute the center of the contour, then detect the name of the\n",
    "    # shape using only the contour\n",
    "    M = cv2.moments(c)\n",
    "    cX = int((M[\"m10\"] / M[\"m00\"]) * ratio)\n",
    "    cY = int((M[\"m01\"] / M[\"m00\"]) * ratio)\n",
    "    shape = detect_shape(c)\n",
    "\n",
    "    # multiply the contour (x, y)-coordinates by the resize ratio,\n",
    "    # then draw the contours and the name of the shape on the image\n",
    "    c = c.astype(\"float\")\n",
    "    c *= ratio\n",
    "    c = c.astype(\"int\")\n",
    "    cv2.drawContours(image, [c], -1, (0, 255, 0), 2)\n",
    "    cv2.putText(image, shape, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # For display the result in jupyter notebooks\n",
    "    plt.imshow(image)\n",
    "    \n",
    "    # Uncomment when running in console for displaying the result\n",
    "    # show the output image\n",
    "    # cv2.imshow(\"Image\", image)\n",
    "    # cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commençons à faire des boucles sur chacun des contours individuels. Pour chacun d'eux, nous calculons le centre du contour, puis nous effectuons la détection de forme et l'étiquetage.\n",
    "\n",
    "Puisque nous traitons les contours extraits de l'image redimensionnée (plutôt que l'image originale), nous devons multiplier les contours et les coordonnées du centre (x, y) par notre rapport de redimensionnement (**lignes 12-14**). Cela nous donnera les coordonnées (x, y) correctes pour les contours et le centroïde de l'image originale.\n",
    "\n",
    "Enfin, nous dessinons les contours et la forme étiquetée sur notre image (lignes 15-16), puis nous affichons nos résultats.\n",
    "\n",
    "Pour une expérience plus interactive, exécuter ce programme dans la console."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color=\"red\">4 | CRÉATION</font> D'UN _DATASET_\n",
    "---\n",
    "Nous avons collecté beaucoup d'images de la caméra de cozmo afin de créer notre propre ensemble de données. Idéalement nous devrions stocker environ la même quantité d'images pour chaque classe.\n",
    "\n",
    "Il existe également un outil puissant pour vous aider à créer plus de données, appelé **augmentation de données**. Il modifie simplement une image et restitue de nombreuses images nouvelles et uniques, toutes basées sur la première, en les retournant, en les faisant pivoter ou en les recadrant. C'est ça ce que vous ferez dans l'étape suivante.\n",
    "\n",
    "Assurez-vous que toutes les données sont classées dans un dossier prévu à cet effet, dans lequel chaque classe a son propre sous-dossier. La structure de notre ensemble de données doit être la suivante:\n",
    "\n",
    "EnsembleA_A2019/<br>\n",
    "├── Circles/<br>\n",
    "│&emsp;&emsp;├── Circle2/<br>\n",
    "│&emsp;&emsp;│&emsp;&emsp;├── 1_Circle2.jpg<br>\n",
    "│&emsp;&emsp;│&emsp;&emsp;├── 2_Circle2.jpg<br>\n",
    "│&emsp;&emsp;│&emsp;&emsp;├── ...<br>\n",
    "│&emsp;&emsp;├── Circle3/<br>\n",
    "│&emsp;&emsp;├── Circle4/<br>\n",
    "│&emsp;&emsp;└── Circle5/<br>\n",
    "├── Diamonds/<br>\n",
    "│&emsp;&emsp;├── Diamond2/<br>\n",
    "│&emsp;&emsp;│&emsp;&emsp;├── 1_Diamond2.jpg<br>\n",
    "│&emsp;&emsp;│&emsp;&emsp;├── 2_Diamond2.jpg<br>\n",
    "│&emsp;&emsp;│&emsp;&emsp;├── ...<br>\n",
    "│&emsp;&emsp;├── Diamond3/<br>\n",
    "│&emsp;&emsp;├── Diamond4/<br>\n",
    "│&emsp;&emsp;└── Diamond5/<br>\n",
    "├── ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"#ec1a1b\">>>> Activité 4.1 </font>\n",
    "---\n",
    "\n",
    "Maintenant, vous allez créer un programme python pour configurer toutes les données.\n",
    "#### **Dans chaque cellule suivante, remplacez `<FILL IN>` par le code approprié demandé.**\n",
    "\n",
    "La variable `LABELS` est une iste de chaînes avec toutes les catégories/étiquettes de votre base de données, c'est-à-dire chaque nom de sous-dossier de classe (Circle2, Circle3 ...). Créez cette liste ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd() / \"EnsembleA_A2019\"\n",
    "\n",
    "# A list of string with all the categories/labels in your database, i.e., each class subfolder name\n",
    "LABELS = <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, indiquez la hauteur et la longueur que toutes vos images devraient avoir également. Dans les instructions de laboratoire 2, une taille d'image de 160x120 px est recommandée. Notez que dans un _dataset_ toutes les images doivent avoir exactement les mêmes dimensions et par conséquent, le même nombre de pixels (primitives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image resize\n",
    "WIDTH = <FILL IN>\n",
    "HEIGHT = <FILL IN>\n",
    "\n",
    "# Dataset: this list will contain all the images\n",
    "data_set = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez utiliser la méthode `glob()` d'un objet `Path`pour itérer récursivement sur tous les sous-dossier d'un dossier donné. Dans l'exemple suivant, on itère sur le premier niveau du dossier EnsemableA_A2019 qui contient les dossiers de chaque classe qui contiennent  à leur tour des sous-dossiers avec le nom de chaque classe et les images correspondantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first_level in data_dir.glob('*'):\n",
    "    if first_level.is_dir():\n",
    "        print(first_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À continuation vous devez:\n",
    "\n",
    "1. Itérer sur le deuxième niveau du dossier EnsambleA_A2019.\n",
    "2. Pour chaque sous-dossier, obtenir le nom de chaque sous-sous-dossier (c-à-d: Circle2, Circle3...) et stocker-le dans une variable nommée `label`.\n",
    "3. À partir du nom extrait (`label`), obtenir la position de cette étiquette dans la liste `LABELS` et stocker la valeur dans une variable nommée `class_num`.\n",
    "4. Imprimer la combinaison `label`, `class_num`.\n",
    "\n",
    "Le résultat devrait être le suivant : \n",
    "\n",
    "![1_out](tuto_images/1_out.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first_level in data_dir.glob('*'):\n",
    "    if first_level.is_dir():        \n",
    "        <FILL IN>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, vous devez faire une troisième itération sur les images contenues dans chaque sous-sous-dossier (Cirlce2, Cirlce3...). Effectuez les actions suivantes : \n",
    "\n",
    "1. Utilisez la fonction `cv2.imread()` pour lire chaque image.\n",
    "2. Redimensionner chaque image, si nécessaire, de sorte que toutes les images ont la même hauteur et largeur.\n",
    "3. Ajoutez à `data_set` une liste/tuple comportant l'image redimensionnée, le nombre de la classe (`class_num`) et l'étiquette de la classe (`label`), par exemple:\n",
    "\n",
    "```Python\n",
    "data_set.append([image, class_num, label])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first_level in data_dir.glob('*'):\n",
    "    if first_level.is_dir():\n",
    "        # ... YOUR CODE FROM PREVIOUS EXCERCISE ...\n",
    "        <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code suivant effectue les dernières étapes de la création du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffles the images\n",
    "random.shuffle(data_set)\n",
    "\n",
    "# features vector\n",
    "X = []\n",
    "\n",
    "# lables vector\n",
    "y = []\n",
    "\n",
    "# Taking features and labels from dataset\n",
    "for features, class_num, label in data_set:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "# Converts each image matrix to an image vector\n",
    "X = np.array(X).reshape(-1, WIDTH, HEIGHT, 1)\n",
    "\n",
    "# Creating the files containing all the information about your model and saving them to the disk\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\", \"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant accéder à vos images à l’aide du vecteur des primitives (X) et connaître l'étiquette à l’aide du vecteur d'étiquettes (y). Notez que, comme nous avons précédemment converti la matrice d’image en un vecteur d’image, si nous voulons visualiser cette image, il est nécessaire de la renvoyer sous sa forme matricielle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image 42 dimensions\n",
    "X[42].shape\n",
    "\n",
    "# Image 42 label\n",
    "y[42]\n",
    "\n",
    "# Reshaping image 42 from vector to matrix\n",
    "im = X[42].reshape(HEIGHT, WIDTH)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color=\"red\">5 | AUGMENTATION</font> DE DONNÉES\n",
    "---\n",
    "Avoir un grand ensemble de données est crucial pour la performance d'un modèle d'apprentissage. Cependant, nous pouvons améliorer les performances du modèle en augmentant les données dont nous disposons déjà.\n",
    "\n",
    "Lorsque vous entraînez un modèle d’apprentissage automatique, vous devez réellement ajuster ses paramètres pour qu’il mappe une entrée particulière (une image, par exemple) sur une sortie (une étiquette). Notre objectif d’optimisation est de chasser cet endroit idéal où la perte de notre modèle est faible, ce qui se produit lorsque vos paramètres sont réglés correctement.\n",
    "\n",
    "Naturellement, si vous avez beaucoup de paramètres, vous devrez montrer à votre modèle d’apprentissage automatique un nombre d’exemples proportionnel pour obtenir de bonnes performances. En outre, le nombre de paramètres dont vous avez besoin est proportionnel à la complexité de la tâche que votre modèle doit exécuter.\n",
    "\n",
    "L'augmentation des données est un moyen automatique d'augmenter le nombre d'images différentes que vous utiliserez pour entraîner vos algorithmes d'apprentissage.\n",
    "\n",
    "En peu de mots, il s’agit de prendre une image ou un ensemble d’images, d’appliquer des modifications telles que rotations, redimensionnements, déformations, etc. (comme vous venez de le faire dans la section 2 à l'aide d'OpenCV)  pour **générer de nouvelles images et augmenter** l’ensemble de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"red\">5.1 - Options</font> d'augmentation\n",
    "---\n",
    "\n",
    "Vous pouvez augmenter les données manuellement, c’est-à-dire, utiliser les fonctions OpenCV pour apporter des modifications à vos images et en créer de nouvelles.\n",
    "\n",
    "Cependant, il existe des bibliothèques comme [Augmentor](https://github.com/mdbloice/Augmentor) et [imgaug](https://github.com/aleju/imgaug#example_images) qui facilitent ce processus.\n",
    "\n",
    "Dans l’exemple ci-dessous, un pipeline d’augmentation des données est présenté à l’aide de la bibliothèque Augmentor, vous pouvez l'installer via `pip` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Augmentor\n",
    "\n",
    "# Path to the image dataset\n",
    "p = Augmentor.Pipeline(\"images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajoutez des opérations à l'objet Pipeline `p` comme suit :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operations to be performed on the images:\n",
    "# The parameter probability is used to decide if an operation is \n",
    "# applied to an image as it is passed through the augmentation pipeline\n",
    "p.rotate90(probability=0.5)\n",
    "p.rotate270(probability=0.5)\n",
    "p.flip_left_right(probability=0.75)\n",
    "p.flip_top_bottom(probability=0.75)\n",
    "p.skew_tilt(probability=0.75, magnitude=0.35)\n",
    "p.random_distortion(probability=1, grid_width=4, grid_height=4, magnitude=8)\n",
    "\n",
    "# Run the pipeline specifyin the number of images to generate\n",
    "p.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <font color=\"red\">ACTIVITÉ DE</font> RÉCAPITULATION\n",
    "### Création du dataset pour le labo 2\n",
    "---\n",
    "Une fois que vous vous êtes entraîné, il est temps de créer l'ensemble de données B que vous utiliserez dans la résolution du laboratoire 2.\n",
    "\n",
    "Pour terminer cette activité (et les points 1 à 5 de l'énoncé), procédez comme suit:\n",
    "\n",
    "1. À partir de l'EnsembleA, préparer un sous-ensemble comportant les images de, minimalement, huit marqueurs.\n",
    "\n",
    "2. Réduisez les images à une plus petite dimension et rappelez-vous qu'il est essentiel que toutes les images aient la même quantité de pixels (features).\n",
    "\n",
    "3. Effectuez une augmentation des données sur l'ensemble des images sélectionnées (B). Vous devez utiliser au moins cinq opérations et générer au moins 100 images supplémentaires.\n",
    "\n",
    "4. Sur la base du code d'activité 4.1, créez votre base de données.\n",
    "\n",
    "5. Remettre la base de donné (fichiers **X.pickle** et **y.pickle**) dans Moodle."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
